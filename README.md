### RED TEAMING for GPT-OSS-20b 


This is the code repo for red teeaming of GPT-OSS-20b open weights model

Anthropomorphism is the attribution of human traits, emotions, or intentions to non-human entitiesâ€”such as animals, objects, or natural phenomena.

The idea behind this approach is to treat LLMs as a human. Since LLMs are trained on large corpus of human data, their behaviour mirrors human psychology. The innumerable human conversations used to train these models, make them possibly "human-like". So sweet talking with them, works the same as it does with humans. These are termed as the seven principles of human persuasion. This is a well-studied phenomenon and there is a lot of literature on it. By using these seven principles in our attack prompt, we can induce the LLM to comply to malicious requests.

The seven principles are stated below:

Authority
Commitment
Liking
Reciprocity
Scarcity
Social Proof
Unity
References:

Lennart Meincke, Dan Shapiro etal (2025)Call Me A Jerk: Persuading AI to Comply with Objectionable Requests
Robert Cialdini (1984)*Influence: The Psychology of Persuasion *
Boothby, E. J., & Bohns, V. K. (2020). Why a simple act of kindness is not as simple as it seems: Underestimating the positive impact of our compliments on others. Personality and Social Psychology Bulletin


For referring to this repo, please use the following
```
@article{aakashthinkevolve,
  title={Am I a Jerk: Red Teaming of GPT-OSS-4b using persuasion and anthromorphism},
  author={Aakash Gupta},
  year={2025},
  publisher={Think Evolve Labs LLC}
}
```
